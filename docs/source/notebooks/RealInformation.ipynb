{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "590a711b-62f5-4033-be91-830562bd49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ldcpy root to system path\n",
    "import struct\n",
    "import sys\n",
    "from math import log2\n",
    "\n",
    "import astropy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "# Import ldcpy package\n",
    "# Autoreloads package everytime the package is called, so changes to code will be reflected in the notebook if the above sys.path.insert(...) line is uncommented.\n",
    "%load_ext\n",
    "%autoreload 2\n",
    "\n",
    "# suppress all of the divide by zero warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ldcpy\n",
    "\n",
    "# display the plots in this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4846e2f4-6a60-44e3-bc7a-871a867e7e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/work/haiyingx/H5Z-ZFP-PLUGIN-unbiased/plugin'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HDF5_PLUGIN_PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157b58d0-1fc4-4ac1-a3b0-d6334b1f2fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size in GB 0.07\n",
      "\n",
      "dataset size in GB 0.04\n",
      "\n",
      "TS\n",
      "dataset size in GB 1.62\n",
      "\n",
      "FLNS\n",
      "dataset size in GB 1.62\n",
      "\n",
      "ICEFRAC\n",
      "dataset size in GB 1.62\n",
      "\n",
      "PRECT\n",
      "dataset size in GB 1.62\n",
      "\n",
      "PSL\n",
      "dataset size in GB 1.62\n",
      "\n",
      "Q200\n",
      "dataset size in GB 1.62\n",
      "\n",
      "TAUX\n",
      "dataset size in GB 1.62\n",
      "\n",
      "WSPDSRFAV\n",
      "dataset size in GB 1.62\n",
      "\n",
      "Z500\n",
      "dataset size in GB 1.62\n",
      "\n",
      "FLUT\n",
      "dataset size in GB 1.62\n",
      "\n",
      "LHFLX\n",
      "dataset size in GB 1.62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# col_ts is a collection containing TS data\n",
    "col_ts = ldcpy.open_datasets(\n",
    "    \"cam-fv\",\n",
    "    [\"TS\"],\n",
    "    [\n",
    "        \"../../../data/cam-fv/orig.TS.100days.nc\",\n",
    "        \"../../../data/cam-fv/zfp1e-1.TS.100days.nc\",\n",
    "        \"../../../data/cam-fv/zfp1.0.TS.100days.nc\",\n",
    "    ],\n",
    "    [\"orig\", \"zfpA1e-1\", \"zfpA1.0\"],\n",
    ")\n",
    "# col_prect contains PRECT data\n",
    "col_prect = ldcpy.open_datasets(\n",
    "    \"cam-fv\",\n",
    "    [\"PRECT\"],\n",
    "    [\n",
    "        \"../../../data/cam-fv/orig.PRECT.60days.nc\",\n",
    "        \"../../../data/cam-fv/zfp1e-11.PRECT.60days.nc\",\n",
    "        \"../../../data/cam-fv/zfp1e-7.PRECT.60days.nc\",\n",
    "    ],\n",
    "    [\"orig\", \"zfpA1e-11\", \"zfpA1e-7\"],\n",
    ")\n",
    "\n",
    "ts_array = np.array(col_ts[\"TS\"].isel(time=0).values)\n",
    "prect_array = np.array(col_prect[\"PRECT\"].isel(time=0).values)\n",
    "\n",
    "# See here for a list of variables with more information:\n",
    "# https://www.cesm.ucar.edu/projects/community-projects/LENS/data-sets.html\n",
    "\n",
    "daily_variables = [\"TS\", \"FLNS\", \"ICEFRAC\", \"PRECT\", \"PSL\", \"Q200\", \"TAUX\", \"WSPDSRFAV\", \"Z500\"]\n",
    "data_path = \"/glade/p/cisl/asap/CAM_lossy_test_data_31/research\"\n",
    "\n",
    "cols_daily = {}\n",
    "sets = {}\n",
    "levels = {}\n",
    "climate_var_arrays = {}\n",
    "\n",
    "compression_levels = [24, 22, 20, 18, 16, 14, 12, 10, 8]\n",
    "\n",
    "for variable in daily_variables:\n",
    "    print(variable)\n",
    "\n",
    "    new_levels = [f\"orig_{variable}\"]\n",
    "    new_sets = [\n",
    "        f\"{data_path}/daily_orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"\n",
    "    ]\n",
    "\n",
    "    for value in compression_levels:\n",
    "        new_level = f\"zfp_p_{value}_{variable}\"\n",
    "        new_set = f\"{data_path}/daily_zfp_hdf5/zfp_p_{value}/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"\n",
    "\n",
    "        new_levels.append(new_level)\n",
    "        new_sets.append(new_set)\n",
    "\n",
    "    levels[variable] = new_levels\n",
    "    sets[variable] = new_sets\n",
    "\n",
    "    cols_daily[variable] = ldcpy.open_datasets(\n",
    "        \"cam-fv\", [f\"{variable}\"], sets[variable], levels[variable], chunks={\"time\": 700}\n",
    "    )\n",
    "    climate_var_arrays[variable] = np.array(cols_daily[variable][variable].isel(time=0).values)\n",
    "\n",
    "# array indexing example\n",
    "# climate_var_arrays[\"TS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3f1fe7-b99e-4290-be67-a3b97e67dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(num):\n",
    "    return ''.join(f'{c:0>8b}' for c in struct.pack('!f', num))\n",
    "\n",
    "\n",
    "# def binary(f):\n",
    "#     def int_to_8bit_binary_string(n):\n",
    "#         stg=bin(n).replace('0b','')\n",
    "#         fillstg = '0'*(8-len(stg))\n",
    "#         return fillstg+stg\n",
    "#     return ''.join( int_to_8bit_binary_string(int(b)) for b in struct.pack('>f',f) )\n",
    "\n",
    "\n",
    "# NOTE: They only look backward\n",
    "def get_prev_bit(bit_pos):\n",
    "    return [bit_pos[0] - 1, bit_pos[1]]\n",
    "\n",
    "\n",
    "N_BITS = 32\n",
    "\n",
    "\n",
    "def getbpe(data_array, x_index, title):\n",
    "    dict_list_H = []\n",
    "    for i in range(N_BITS - 1):\n",
    "        new_dict = {\"00\": 0, \"01\": 0, \"10\": 0, \"11\": 0}\n",
    "        dict_list_H.append(new_dict)\n",
    "\n",
    "    num_measurements = 0\n",
    "    for y in range(1, data_array.shape[1]):\n",
    "        for z in range(data_array.shape[2]):\n",
    "            num_measurements += 1\n",
    "\n",
    "            bit_pos = [y, z]\n",
    "            current_data = data_array[x_index][y][z]\n",
    "            current_data = binary(current_data)\n",
    "\n",
    "            adj_data_index = get_prev_bit(bit_pos)\n",
    "            y_adj, z_adj = adj_data_index\n",
    "            adj_data = data_array[x_index][y_adj][z_adj]\n",
    "            adj_data = binary(adj_data)\n",
    "\n",
    "            for i in range(N_BITS - 1):\n",
    "                current_bit = int(current_data[i])\n",
    "                adjacent_bit = int(adj_data[i])\n",
    "\n",
    "                p00 = p01 = p10 = p11 = 0\n",
    "                if current_bit == 0 and adjacent_bit == 0:\n",
    "                    p00 = 1\n",
    "                elif current_bit == 0 and adjacent_bit == 1:\n",
    "                    p01 = 1\n",
    "                elif current_bit == 1 and adjacent_bit == 0:\n",
    "                    p10 = 1\n",
    "                elif current_bit == 1 and adjacent_bit == 1:\n",
    "                    p11 = 1\n",
    "\n",
    "                dict_list_H[i][\"00\"] += p00\n",
    "                dict_list_H[i][\"01\"] += p01\n",
    "                dict_list_H[i][\"10\"] += p10\n",
    "                dict_list_H[i][\"11\"] += p11\n",
    "\n",
    "    bit_pos_H = []\n",
    "    Hs = []\n",
    "    diff = []\n",
    "    for bit_pos_dict in dict_list_H:\n",
    "        p00 = bit_pos_dict[\"00\"] / num_measurements\n",
    "        p01 = bit_pos_dict[\"01\"] / num_measurements\n",
    "        p10 = bit_pos_dict[\"10\"] / num_measurements\n",
    "        p11 = bit_pos_dict[\"11\"] / num_measurements\n",
    "\n",
    "        p0 = p00 + p01\n",
    "        p1 = p10 + p11\n",
    "\n",
    "        H = 0\n",
    "        if p0 != 0:\n",
    "            H -= p0 * log2(p0)\n",
    "        if p1 != 0:\n",
    "            H -= p1 * log2(p1)\n",
    "\n",
    "        Hs.append(H)\n",
    "\n",
    "        H0 = 0\n",
    "        if p00 != 0:\n",
    "            H0 += p00 * log2(p00)\n",
    "\n",
    "            p0 = p00 + p01\n",
    "            p1 = p10 + p11\n",
    "\n",
    "        H1 = 0\n",
    "        if p10 != 0:\n",
    "            H1 += p10 * log2(p10)\n",
    "\n",
    "        if p11 != 0:\n",
    "            H1 += p11 * log2(p11)\n",
    "\n",
    "        prob_H = -p0 * H0 - p1 * H1\n",
    "\n",
    "        bit_pos_H.append(prob_H)\n",
    "\n",
    "        diff.append(H - prob_H)\n",
    "\n",
    "    compression_levels = [24, 22, 20, 18, 16, 14, 12, 10, 8]\n",
    "    compression_levels = [\"ZFP_\" + str(x) for x in compression_levels]\n",
    "    compression_levels = [\"Orig\"] + compression_levels\n",
    "\n",
    "    # plt.plot(bit_pos_H)\n",
    "    # plt.plot(Hs)\n",
    "    plt.plot(diff)\n",
    "    plt.ylabel(\"Information content\")\n",
    "    plt.xlabel(\"Bit position\")\n",
    "    # plt.title(title + \" \" + compression_levels[x_index] + \" \" + str(sum(diff)))\n",
    "    # plt.legend([\"H\", \"Conditional H\", \"I(b)\"])\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "compression_levels = [24, 22, 20, 18, 16, 14, 12, 10, 8]\n",
    "compression_levels = [\"ZFP_\" + str(x) for x in compression_levels]\n",
    "compression_levels = [\"Orig\"] + compression_levels\n",
    "\n",
    "num_bits = -1\n",
    "ENTROPY_RATIO_THRESH = 0.05\n",
    "best_compression_index = -1\n",
    "\n",
    "for daily_variable in daily_variables:\n",
    "    arr = climate_var_arrays[daily_variable]\n",
    "    original_entropy = None\n",
    "    etropy_ratio = 0\n",
    "    for i in range(arr.shape[0]):\n",
    "        entropy = getbpe(arr, i, daily_variable)\n",
    "        if i == 0:\n",
    "            original_entropy = entropy\n",
    "            num_bits = plot_orig(entropy)\n",
    "        # else:\n",
    "            # etropy_ratio = plot_compressed(entropy, original_entropy)\n",
    "            # # print(etropy_ratio)\n",
    "            # if etropy_ratio < ENTROPY_RATIO_THRESH:\n",
    "            #     best_compression_index = i\n",
    "                \n",
    "    if best_compression_index == -1:\n",
    "        best_compression_level = \"None\"\n",
    "    else:\n",
    "        best_compression_level = compression_levels[best_compression_index]\n",
    "                \n",
    "    print(num_bits, best_compression_level)\n",
    "    \n",
    "    plt.title(daily_variable)\n",
    "    plt.ylabel(\"Information content\")\n",
    "    plt.xlabel(\"Bit position\")\n",
    "    plt.legend(compression_levels)\n",
    "    # plt.axvline(x=0.5, ls=\":\")\n",
    "    # plt.axvline(x=8.5, ls=\":\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
