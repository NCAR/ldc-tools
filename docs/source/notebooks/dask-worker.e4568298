distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.99:43107'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.99:38565'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.99:36333'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.99:45057'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.99:32869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.99:34677'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.99:37951'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.99:41653'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.99:41819'
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-u2vbrego', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-crxrg9yg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-h3eat8zs', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-h8_mg079', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-13repm54', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-s1d8whxi', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-i1iicnq1', purging
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.99:45445
distributed.worker - INFO -          Listening to:   tcp://10.148.10.99:45445
distributed.worker - INFO -          dashboard at:         10.148.10.99:39709
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-h7wn723g
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.99:32885
distributed.worker - INFO -          Listening to:   tcp://10.148.10.99:32885
distributed.worker - INFO -          dashboard at:         10.148.10.99:38529
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-uaxcitt2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.99:46259
distributed.worker - INFO -          Listening to:   tcp://10.148.10.99:46259
distributed.worker - INFO -          dashboard at:         10.148.10.99:45817
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-llmlj2z6
distributed.worker - INFO - -------------------------------------------------
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.99:34015
distributed.worker - INFO -          Listening to:   tcp://10.148.10.99:34015
distributed.worker - INFO -          dashboard at:         10.148.10.99:38955
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-hundhvmd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.99:36665
distributed.worker - INFO -          Listening to:   tcp://10.148.10.99:36665
distributed.worker - INFO -          dashboard at:         10.148.10.99:45187
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.99:35343
distributed.worker - INFO -          Listening to:   tcp://10.148.10.99:35343
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -          dashboard at:         10.148.10.99:33083
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:45903
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-zt84dfvh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-01qypjr7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.99:46703
distributed.worker - INFO -          Listening to:   tcp://10.148.10.99:46703
distributed.worker - INFO -          dashboard at:         10.148.10.99:34267
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-_nue64a5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.99:32791
distributed.worker - INFO -          Listening to:   tcp://10.148.10.99:32791
distributed.worker - INFO -          dashboard at:         10.148.10.99:42041
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-28iky5qd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.99:33455
distributed.worker - INFO -          Listening to:   tcp://10.148.10.99:33455
distributed.worker - INFO -          dashboard at:         10.148.10.99:41757
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-wn54dsd6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:45903
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Stopping worker at tcp://10.148.10.99:35343
distributed.worker - INFO - Stopping worker at tcp://10.148.10.99:36665
distributed.worker - INFO - Stopping worker at tcp://10.148.10.99:33455
distributed.worker - INFO - Stopping worker at tcp://10.148.10.99:32791
distributed.worker - INFO - Stopping worker at tcp://10.148.10.99:46703
distributed.worker - ERROR - failed during get data with tcp://10.148.10.99:45445 -> tcp://10.148.10.14:35997
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: BrokenPipeError: [Errno 32] Broken pipe
distributed.core - INFO - Lost connection to 'tcp://10.148.10.14:59766': in <closed TCP>: BrokenPipeError: [Errno 32] Broken pipe
distributed.worker - ERROR - failed during get data with tcp://10.148.10.99:32791 -> tcp://10.148.10.14:35997
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - failed during get data with tcp://10.148.10.99:46703 -> tcp://10.148.10.14:35997
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.8:34537
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x2b8224a379d0>>, <Task finished coro=<Worker.gather_dep() done, defined at /ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py:1935> exception=CommClosedError()>)
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 743, in _run_callback
    ret = callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 767, in _discard_future_result
    future.result()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 2040, in gather_dep
    {"op": "missing-data", "errant_worker": worker, "key": d}
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Dependent not found: ('rechunk-split-164ea1cdd43c4a68328c983d85ca98ab', 252) 0 .  Asking scheduler
distributed.worker - ERROR - failed during get data with tcp://10.148.10.99:32791 -> tcp://10.148.10.99:46703
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - failed during get data with tcp://10.148.10.99:45445 -> tcp://10.148.10.99:46703
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: BrokenPipeError: [Errno 32] Broken pipe
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.8:34537
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.core - INFO - Lost connection to 'tcp://10.148.10.99:51828': in <closed TCP>: BrokenPipeError: [Errno 32] Broken pipe
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.14:36153
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.14:41445
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.99:45445
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.99:32791
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.14:35997
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 198, in read
    n = await stream.read_into(frame)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.99:43107'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.99:38565'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.99:36333'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.99:45057'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.99:32869'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.99:34677'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.99:37951'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.99:41653'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.99:41819'
distributed.nanny - INFO - Worker process 2903 was killed by signal 15
distributed.nanny - INFO - Worker process 2887 was killed by signal 15
distributed.nanny - INFO - Worker process 2898 was killed by signal 15
distributed.nanny - INFO - Worker process 2892 was killed by signal 15
distributed.nanny - INFO - Worker process 2885 was killed by signal 15
distributed.nanny - INFO - Worker process 2901 was killed by signal 15
distributed.nanny - INFO - Worker process 2888 was killed by signal 15
distributed.nanny - INFO - Worker process 2884 was killed by signal 15
distributed.nanny - INFO - Worker process 2895 was killed by signal 15
distributed.dask_worker - INFO - End worker
