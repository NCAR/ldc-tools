distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.16:46641'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.16:45121'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.16:42687'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.16:46179'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.16:35365'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.16:44055'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.16:32907'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.16:39479'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.16:33469'
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:45009
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:38209
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:39203
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:38313
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:45009
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:46683
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:39203
distributed.worker - INFO -          dashboard at:         10.148.10.16:34307
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:38209
distributed.worker - INFO -          dashboard at:         10.148.10.16:44471
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:38313
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.148.10.16:43215
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:46683
distributed.worker - INFO -          dashboard at:         10.148.10.16:35801
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO -          dashboard at:         10.148.10.16:34539
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-zm3i61cp
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-rvtl4d9l
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-i8pa2ys6
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-4sk086mw
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-91hl_ry6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:45855
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:45855
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:40911
distributed.worker - INFO -          dashboard at:         10.148.10.16:40211
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:40911
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.148.10.16:34951
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-553c17dd
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-gueq1wy1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:39907
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:39907
distributed.worker - INFO -          dashboard at:         10.148.10.16:36953
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-862n80_2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:45545
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:45545
distributed.worker - INFO -          dashboard at:         10.148.10.16:42741
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-8_jkscie
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:39203 -> tcp://10.148.11.40:42341
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:39907 -> tcp://10.148.11.40:33361
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:38209 -> tcp://10.148.11.40:33361
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 251, in write
    await future
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 255, in write
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:45545 -> tcp://10.148.11.40:33587
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:53442': in <closed TCP>: Stream is closed
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:36856': in <closed TCP>: Stream is closed
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:46964': in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:33024': in <closed TCP>: Stream is closed
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:45545 -> tcp://10.148.11.40:33361
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 251, in write
    await future
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 255, in write
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:33034': in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:38209 -> tcp://10.148.11.40:39357
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:46960': in <closed TCP>: Stream is closed
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:45545 -> tcp://10.148.11.40:39357
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 251, in write
    await future
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 255, in write
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:33028': in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:40911 -> tcp://10.148.11.40:39357
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:37600': in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:45855 -> tcp://10.148.11.40:39357
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 251, in write
    await future
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1248, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 255, in write
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:56138': in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.78 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 71% memory usage. Resuming worker. Process memory: 8.71 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.75 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.73 GB -- Worker memory limit: 12.11 GB
distributed.utils_perf - INFO - full garbage collection released 184.61 MB from 572 reference cycles (threshold: 10.00 MB)
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.73 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 9.64 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.95 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 10.44 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.93 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.73 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 9.36 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 84% memory usage. Pausing worker.  Process memory: 10.22 GB -- Worker memory limit: 12.11 GB
distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting
distributed.nanny - INFO - Worker process 10029 was killed by signal 15
distributed.nanny - WARNING - Restarting worker
distributed.worker - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 9.23 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 74% memory usage. Resuming worker. Process memory: 8.97 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 9.37 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 9.63 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 9.35 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.98 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 10.51 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 84% memory usage. Pausing worker.  Process memory: 10.20 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 9.24 GB -- Worker memory limit: 12.11 GB
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-6efr636s', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-x8_img4k', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-rbb6q14x', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-av7ugfii', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-bfbki1ha', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-qodar29d', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-9zm_y7lz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-td1u7iov', purging
distributed.worker - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 10.04 GB -- Worker memory limit: 12.11 GB
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-mwi0m2du', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-mha4df_h', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-abi1msre', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-6or20uz0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-jy3gouo8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-kk9jg7ff', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-8gpflb22', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-_pxy53as', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-atc8vq3c', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-1gmri4gs', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-2zb_3jsp', purging
distributed.worker - WARNING - Worker is at 83% memory usage. Pausing worker.  Process memory: 10.14 GB -- Worker memory limit: 12.11 GB
distributed.utils_perf - INFO - full garbage collection released 120.27 MB from 992 reference cycles (threshold: 10.00 MB)
distributed.worker - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 10.04 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 9.91 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 9.82 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 84% memory usage. Pausing worker.  Process memory: 10.20 GB -- Worker memory limit: 12.11 GB
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:41087
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:41087
distributed.worker - INFO -          dashboard at:         10.148.10.16:33879
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-e852i3er
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting
distributed.worker - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 9.68 GB -- Worker memory limit: 12.11 GB
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:45545 -> tcp://10.148.10.16:46683
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.core - INFO - Lost connection to 'tcp://10.148.10.16:35690': in <closed TCP>: Stream is closed
distributed.nanny - INFO - Worker process 10028 was killed by signal 15
distributed.worker - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 9.99 GB -- Worker memory limit: 12.11 GB
distributed.nanny - WARNING - Restarting worker
distributed.worker - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 9.43 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 9.38 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 75% memory usage. Resuming worker. Process memory: 9.13 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 9.83 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.70 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 9.25 GB -- Worker memory limit: 12.11 GB
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:37549
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:37549
distributed.worker - INFO -          dashboard at:         10.148.10.16:37063
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-iahjthx8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 9.82 GB -- Worker memory limit: 12.11 GB
distributed.worker - ERROR - failed during get data with tcp://10.148.10.16:37549 -> tcp://10.148.11.40:45041
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1249, in get_data
    response = await comm.read(deserializers=serializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 123, in convert_stream_closed_error
    raise CommClosedError("in %s: %s" % (obj, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed
distributed.core - INFO - Lost connection to 'tcp://10.148.11.40:49716': in <closed TCP>: Stream is closed
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.69 GB -- Worker memory limit: 12.11 GB
distributed.utils_perf - INFO - full garbage collection released 110.58 MB from 408 reference cycles (threshold: 10.00 MB)
distributed.worker - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 9.62 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 9.45 GB -- Worker memory limit: 12.11 GB
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1671, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1894, in put_key_in_memory
    self.data[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 87, in __setitem__
    self.fast[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 70, in __setitem__
    self.evict()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 89, in evict
    cb(k, v)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 60, in fast_to_slow
    self.slow[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/func.py", line 41, in __setitem__
    self.d[key] = self.dump(value)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/file.py", line 79, in __setitem__
    with open(os.path.join(self.directory, _safe_key(key)), "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-8_jkscie/storage/%28%27concatenate-9306761062214e1a899c27fe99e647bd%27%2C%202%2C%202%2C%200%2C%200%29'
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1671, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1894, in put_key_in_memory
    self.data[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 87, in __setitem__
    self.fast[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 70, in __setitem__
    self.evict()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 89, in evict
    cb(k, v)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 60, in fast_to_slow
    self.slow[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/func.py", line 41, in __setitem__
    self.d[key] = self.dump(value)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/file.py", line 79, in __setitem__
    with open(os.path.join(self.directory, _safe_key(key)), "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-8_jkscie/storage/%28%27concatenate-9306761062214e1a899c27fe99e647bd%27%2C%202%2C%204%2C%200%2C%200%29'
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1671, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1894, in put_key_in_memory
    self.data[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 87, in __setitem__
    self.fast[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 70, in __setitem__
    self.evict()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 89, in evict
    cb(k, v)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 60, in fast_to_slow
    self.slow[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/func.py", line 41, in __setitem__
    self.d[key] = self.dump(value)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/file.py", line 79, in __setitem__
    with open(os.path.join(self.directory, _safe_key(key)), "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-rvtl4d9l/storage/%28%27concatenate-9306761062214e1a899c27fe99e647bd%27%2C%202%2C%2027%2C%200%2C%200%29'
distributed.worker - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 9.53 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 10.01 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 83% memory usage. Pausing worker.  Process memory: 10.08 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 9.92 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 9.43 GB -- Worker memory limit: 12.11 GB
distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1671, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1894, in put_key_in_memory
    self.data[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 87, in __setitem__
    self.fast[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 70, in __setitem__
    self.evict()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 89, in evict
    cb(k, v)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 60, in fast_to_slow
    self.slow[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/func.py", line 41, in __setitem__
    self.d[key] = self.dump(value)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/file.py", line 79, in __setitem__
    with open(os.path.join(self.directory, _safe_key(key)), "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-8_jkscie/storage/%28%27concatenate-9306761062214e1a899c27fe99e647bd%27%2C%202%2C%2010%2C%200%2C%200%29'
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1671, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1894, in put_key_in_memory
    self.data[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 87, in __setitem__
    self.fast[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 70, in __setitem__
    self.evict()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 89, in evict
    cb(k, v)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 60, in fast_to_slow
    self.slow[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/func.py", line 41, in __setitem__
    self.d[key] = self.dump(value)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/file.py", line 79, in __setitem__
    with open(os.path.join(self.directory, _safe_key(key)), "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-8_jkscie/storage/%28%27concatenate-9306761062214e1a899c27fe99e647bd%27%2C%202%2C%2034%2C%200%2C%200%29'
distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting
distributed.worker - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 10.50 GB -- Worker memory limit: 12.11 GB
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:39203
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:39203
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:39203
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-703ae277aafa55203021f8461b5a0983', 1, 41, 0, 0)
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-a2d9c150534c902988d0de741b5918f8', 0, 8, 0, 1)
distributed.worker - INFO - Dependent not found: ('rechunk-split-703ae277aafa55203021f8461b5a0983', 205) 0 .  Asking scheduler
distributed.worker - INFO - Dependent not found: ('rechunk-split-a2d9c150534c902988d0de741b5918f8', 654) 0 .  Asking scheduler
distributed.worker - INFO - Dependent not found: ('rechunk-split-a2d9c150534c902988d0de741b5918f8', 655) 0 .  Asking scheduler
distributed.nanny - INFO - Worker process 10019 was killed by signal 15
distributed.nanny - WARNING - Restarting worker
distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:39907
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:39907
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.nanny - INFO - Worker process 10037 was killed by signal 15
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-a2d9c150534c902988d0de741b5918f8', 1, 8, 0, 1)
distributed.worker - INFO - Dependent not found: ('rechunk-split-a2d9c150534c902988d0de741b5918f8', 1379) 0 .  Asking scheduler
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-a2d9c150534c902988d0de741b5918f8', 1, 8, 1, 2)
distributed.worker - INFO - Dependent not found: ('rechunk-split-a2d9c150534c902988d0de741b5918f8', 1403) 0 .  Asking scheduler
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:39907
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:39907
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-a2d9c150534c902988d0de741b5918f8', 1, 8, 3, 2)
distributed.worker - INFO - Dependent not found: ('rechunk-split-a2d9c150534c902988d0de741b5918f8', 1439) 0 .  Asking scheduler
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-a2d9c150534c902988d0de741b5918f8', 1, 8, 3, 1)
distributed.worker - INFO - Dependent not found: ('rechunk-split-a2d9c150534c902988d0de741b5918f8', 1433) 0 .  Asking scheduler
distributed.nanny - WARNING - Restarting worker
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-a2d9c150534c902988d0de741b5918f8', 1, 8, 1, 2)
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-jkbjtluh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-bqq2j6cz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-qcjgru2p', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-wxsq2wqq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-uap3_g94', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-3j4eavwz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-9f7vc_v3', purging
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45545
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-703ae277aafa55203021f8461b5a0983', 0, 5, 0, 0)
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45545
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45545
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - INFO - Dependent not found: ('rechunk-split-703ae277aafa55203021f8461b5a0983', 11) 0 .  Asking scheduler
distributed.nanny - INFO - Worker process 10032 was killed by signal 15
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-ap8f0obw', purging
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45545
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-703ae277aafa55203021f8461b5a0983', 0, 11, 0, 0)
distributed.worker - INFO - Dependent not found: ('rechunk-split-703ae277aafa55203021f8461b5a0983', 25) 0 .  Asking scheduler
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-_3pgfz47', purging
distributed.nanny - WARNING - Restarting worker
distributed.worker - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 9.52 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 9.68 GB -- Worker memory limit: 12.11 GB
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:37779
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:37779
distributed.worker - INFO -          dashboard at:         10.148.10.16:43987
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-gyn3nw2m
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:39595
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:39595
distributed.worker - INFO -          dashboard at:         10.148.10.16:38825
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-9e6rszj4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - WARNING - Worker is at 84% memory usage. Pausing worker.  Process memory: 10.21 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.70 GB -- Worker memory limit: 12.11 GB
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:46737
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:46737
distributed.worker - INFO -          dashboard at:         10.148.10.16:39501
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-yd8r744_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 9.69 GB -- Worker memory limit: 12.11 GB
distributed.worker - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 9.78 GB -- Worker memory limit: 12.11 GB
distributed.utils_perf - INFO - full garbage collection released 321.64 MB from 597 reference cycles (threshold: 10.00 MB)
distributed.worker - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 9.62 GB -- Worker memory limit: 12.11 GB
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1671, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1894, in put_key_in_memory
    self.data[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 87, in __setitem__
    self.fast[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 70, in __setitem__
    self.evict()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 89, in evict
    cb(k, v)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 60, in fast_to_slow
    self.slow[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/func.py", line 41, in __setitem__
    self.d[key] = self.dump(value)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/file.py", line 79, in __setitem__
    with open(os.path.join(self.directory, _safe_key(key)), "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-553c17dd/storage/%28%27concatenate-9306761062214e1a899c27fe99e647bd%27%2C%202%2C%205%2C%200%2C%200%29'
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1671, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1894, in put_key_in_memory
    self.data[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 87, in __setitem__
    self.fast[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 70, in __setitem__
    self.evict()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 89, in evict
    cb(k, v)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 60, in fast_to_slow
    self.slow[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/func.py", line 41, in __setitem__
    self.d[key] = self.dump(value)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/file.py", line 79, in __setitem__
    with open(os.path.join(self.directory, _safe_key(key)), "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-553c17dd/storage/%28%27concatenate-9306761062214e1a899c27fe99e647bd%27%2C%202%2C%209%2C%200%2C%200%29'
distributed.worker - INFO - Failed to put key in memory
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1671, in transition_executing_done
    self.put_key_in_memory(key, value, transition=False)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1894, in put_key_in_memory
    self.data[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 87, in __setitem__
    self.fast[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 70, in __setitem__
    self.evict()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/lru.py", line 89, in evict
    cb(k, v)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/buffer.py", line 60, in fast_to_slow
    self.slow[key] = value
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/func.py", line 41, in __setitem__
    self.d[key] = self.dump(value)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/zict/file.py", line 79, in __setitem__
    with open(os.path.join(self.directory, _safe_key(key)), "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-553c17dd/storage/%28%27concatenate-9306761062214e1a899c27fe99e647bd%27%2C%202%2C%2015%2C%200%2C%200%29'
distributed.worker - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 9.91 GB -- Worker memory limit: 12.11 GB
distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45855
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45855
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45855
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-703ae277aafa55203021f8461b5a0983', 0, 1, 0, 0)
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-703ae277aafa55203021f8461b5a0983', 0, 45, 0, 0)
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-703ae277aafa55203021f8461b5a0983', 1, 13, 0, 0)
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45855
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - INFO - Dependent not found: ('rechunk-split-703ae277aafa55203021f8461b5a0983', 2) 0 .  Asking scheduler
distributed.worker - INFO - Dependent not found: ('rechunk-split-703ae277aafa55203021f8461b5a0983', 143) 0 .  Asking scheduler
distributed.worker - INFO - Dependent not found: ('rechunk-split-703ae277aafa55203021f8461b5a0983', 100) 0 .  Asking scheduler
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-703ae277aafa55203021f8461b5a0983', 0, 24, 0, 0)
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-703ae277aafa55203021f8461b5a0983', 1, 29, 0, 0)
distributed.worker - INFO - Dependent not found: ('rechunk-split-703ae277aafa55203021f8461b5a0983', 52) 0 .  Asking scheduler
distributed.nanny - INFO - Worker process 10026 was killed by signal 15
distributed.worker - INFO - Dependent not found: ('rechunk-split-703ae277aafa55203021f8461b5a0983', 179) 0 .  Asking scheduler
distributed.nanny - WARNING - Restarting worker
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45855
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - ERROR - Worker stream died during communication: tcp://10.148.10.16:45855
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 188, in read
    n_frames = await stream.read_bytes(8)
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 1953, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3222, in get_data_from_worker
    return await retry_operation(_get_data, operation="get_data_from_worker")
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 391, in retry_operation
    operation=operation,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/utils_comm.py", line 379, in retry
    return await coro()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 3209, in _get_data
    max_connections=max_connections,
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/core.py", line 541, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 208, in read
    convert_stream_closed_error(self, e)
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/comm/tcp.py", line 121, in convert_stream_closed_error
    raise CommClosedError("in %s: %s: %s" % (obj, exc.__class__.__name__, exc))
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - INFO - Can't find dependencies for key ('rechunk-merge-703ae277aafa55203021f8461b5a0983', 1, 33, 0, 0)
distributed.worker - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 9.36 GB -- Worker memory limit: 12.11 GB
distributed.worker - INFO -       Start worker at:   tcp://10.148.10.16:37319
distributed.worker - INFO -          Listening to:   tcp://10.148.10.16:37319
distributed.worker - INFO -          dashboard at:         10.148.10.16:33625
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-qc_sx9x9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:36191
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Stopping worker at tcp://10.148.10.16:39595
distributed.worker - INFO - Stopping worker at tcp://10.148.10.16:37779
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.16:46641'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.16:45121'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.16:42687'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.16:46179'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.16:35365'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.16:44055'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.16:32907'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.16:39479'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.16:33469'
distributed.nanny - INFO - Worker process 10844 was killed by signal 15
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 48 leaked semaphores to clean up at shutdown
  len(cache))
