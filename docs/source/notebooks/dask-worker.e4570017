distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.225:43187'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.225:44015'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.225:40797'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.225:33713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.225:46679'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.225:44995'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.225:37033'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.225:43759'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.225:38495'
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-35rbxhxo', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-1zct5g4o', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-7kzaq_j2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-qyezz7ns', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-flgitl1p', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-xa4dynkb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-qmgrpv52', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-xpcatu7t', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-_p1ue1gy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-tzz2y8ek', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-gt45pjpq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-b4fuh5uz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-pv5744te', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-tu1c_7s4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-o8p77pcd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-94270fn_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-k_xuqdyl', purging
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.225:43585
distributed.worker - INFO -          Listening to:  tcp://10.148.10.225:43585
distributed.worker - INFO -          dashboard at:        10.148.10.225:44133
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.225:36765
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-g_nsbl7x
distributed.worker - INFO -          Listening to:  tcp://10.148.10.225:36765
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        10.148.10.225:43481
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.225:39921
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-hhb1c3ad
distributed.worker - INFO -          Listening to:  tcp://10.148.10.225:39921
distributed.worker - INFO -          dashboard at:        10.148.10.225:33463
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.225:43495
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:34923
distributed.worker - INFO -          Listening to:  tcp://10.148.10.225:43495
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.225:36075
distributed.worker - INFO -          dashboard at:        10.148.10.225:35567
distributed.worker - INFO -          Listening to:  tcp://10.148.10.225:36075
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:34923
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.225:34297
distributed.worker - INFO -               Threads:                          4
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.225:45529
distributed.worker - INFO -          dashboard at:        10.148.10.225:37835
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.225:44129
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.225:34923
distributed.worker - INFO -          Listening to:  tcp://10.148.10.225:34297
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:34923
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -          Listening to:  tcp://10.148.10.225:45529
distributed.worker - INFO -          Listening to:  tcp://10.148.10.225:44129
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-8_pcg268
distributed.worker - INFO -          dashboard at:        10.148.10.225:43355
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -          dashboard at:        10.148.10.225:39605
distributed.worker - INFO -          dashboard at:        10.148.10.225:44771
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:34923
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:34923
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-9ji07osu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -          Listening to:  tcp://10.148.10.225:34923
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-m6ljqbv3
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        10.148.10.225:41353
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-ktwhjsjv
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-6mc4qkui
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-6nq4jhn0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-wg1h90zf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:34923
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.utils_perf - INFO - full garbage collection released 16.97 MB from 671 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 10.84 MB from 722 reference cycles (threshold: 10.00 MB)
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b0dd91cf4d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2ab1e9b574d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b6df81884d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b47927bc710>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2ad1748ef290>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b35707c44d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2ad9e030c4d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2ba55c6cf4d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2aea6b5034d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://10.148.10.225:43585
distributed.worker - INFO - Stopping worker at tcp://10.148.10.225:34297
distributed.worker - INFO - Stopping worker at tcp://10.148.10.225:43495
distributed.worker - INFO - Stopping worker at tcp://10.148.10.225:45529
distributed.worker - INFO - Stopping worker at tcp://10.148.10.225:39921
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.148.10.225:44129
distributed.worker - INFO - Stopping worker at tcp://10.148.10.225:36765
distributed.worker - INFO - Stopping worker at tcp://10.148.10.225:36075
distributed.worker - INFO - Stopping worker at tcp://10.148.10.225:34923
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.225:44015'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.225:43187'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.225:40797'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.225:46679'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.225:37033'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.225:43759'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.225:44995'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.225:38495'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.225:33713'
distributed.dask_worker - INFO - End worker
