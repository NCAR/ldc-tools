distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.200:35791'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.200:35005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.200:46091'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.200:44043'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.200:33173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.200:45705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.200:39413'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.200:35149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.7.200:39471'
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.200:35977
distributed.worker - INFO -          Listening to:   tcp://10.148.7.200:35977
distributed.worker - INFO -          dashboard at:         10.148.7.200:39795
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-9nz2tqic
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.200:40355
distributed.worker - INFO -          Listening to:   tcp://10.148.7.200:40355
distributed.worker - INFO -          dashboard at:         10.148.7.200:38915
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-aane3mmi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.200:40685
distributed.worker - INFO -          Listening to:   tcp://10.148.7.200:40685
distributed.worker - INFO -          dashboard at:         10.148.7.200:43919
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-xw2sy31s
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.200:45507
distributed.worker - INFO -          Listening to:   tcp://10.148.7.200:45507
distributed.worker - INFO -          dashboard at:         10.148.7.200:41471
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-wn_xzrwe
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.200:41553
distributed.worker - INFO -          Listening to:   tcp://10.148.7.200:41553
distributed.worker - INFO -          dashboard at:         10.148.7.200:37643
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-yyt0vxtj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.200:44787
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.200:41795
distributed.worker - INFO -          Listening to:   tcp://10.148.7.200:41795
distributed.worker - INFO -          Listening to:   tcp://10.148.7.200:44787
distributed.worker - INFO -          dashboard at:         10.148.7.200:38035
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:39465
distributed.worker - INFO -          dashboard at:         10.148.7.200:39431
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-q2wjp6ic
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-6_7y9kcb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.200:44509
distributed.worker - INFO -          Listening to:   tcp://10.148.7.200:44509
distributed.worker - INFO -          dashboard at:         10.148.7.200:40939
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-c7epov07
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.148.7.200:33425
distributed.worker - INFO -          Listening to:   tcp://10.148.7.200:33425
distributed.worker - INFO -          dashboard at:         10.148.7.200:35695
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-hwqvhpgi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:39465
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b84123b2710>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b0f871004d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2aad9941fa70>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b4649ed0b90>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b9dbcbbf4d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b2df04954d0>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b08df1e0b90>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2ad4da634b90>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x2b542aca5c20>
Traceback (most recent call last):
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/worker.py", line 652, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}),
  File "/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/site-packages/distributed/batched.py", line 117, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://10.148.7.200:45507
distributed.worker - INFO - Stopping worker at tcp://10.148.7.200:44509
distributed.worker - INFO - Stopping worker at tcp://10.148.7.200:40355
distributed.worker - INFO - Stopping worker at tcp://10.148.7.200:40685
distributed.worker - INFO - Stopping worker at tcp://10.148.7.200:44787
distributed.worker - INFO - Stopping worker at tcp://10.148.7.200:41553
distributed.worker - INFO - Stopping worker at tcp://10.148.7.200:33425
distributed.worker - INFO - Stopping worker at tcp://10.148.7.200:35977
distributed.worker - INFO - Stopping worker at tcp://10.148.7.200:41795
distributed.diskutils - ERROR - Failed to remove '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-wn_xzrwe' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-wn_xzrwe'
distributed.diskutils - ERROR - Failed to remove '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-xw2sy31s' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-xw2sy31s'
distributed.diskutils - ERROR - Failed to remove '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-c7epov07' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-c7epov07'
distributed.diskutils - ERROR - Failed to remove '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-aane3mmi' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-aane3mmi'
distributed.diskutils - ERROR - Failed to remove '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-6_7y9kcb' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-6_7y9kcb'
distributed.diskutils - ERROR - Failed to remove '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-yyt0vxtj' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-yyt0vxtj'
distributed.diskutils - ERROR - Failed to remove '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-9nz2tqic' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-9nz2tqic'
distributed.diskutils - ERROR - Failed to remove '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-hwqvhpgi' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-hwqvhpgi'
distributed.diskutils - ERROR - Failed to remove '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-q2wjp6ic' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-q2wjp6ic'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.200:33173'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.200:39413'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.200:39471'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.200:46091'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.200:35791'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.200:35149'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.200:35005'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.200:44043'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.7.200:45705'
distributed.dask_worker - INFO - End worker
