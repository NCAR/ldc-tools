distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.199:40769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.199:43573'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.199:41219'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.199:41997'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.199:34097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.199:37151'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.199:33485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.199:42233'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.148.10.199:33561'
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-o7cd8rp0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-kwr0xqgo', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-cy3w3re2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-d6zq_mi2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-5jr3wok1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-7kbqfj6_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-wdr7z30p', purging
distributed.diskutils - INFO - Found stale lock file and directory '/glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-ozjfnoqm', purging
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.199:39281
distributed.worker - INFO -          Listening to:  tcp://10.148.10.199:39281
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.199:44033
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.199:38935
distributed.worker - INFO -          dashboard at:        10.148.10.199:39351
distributed.worker - INFO -          Listening to:  tcp://10.148.10.199:44033
distributed.worker - INFO -          Listening to:  tcp://10.148.10.199:38935
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:44001
distributed.worker - INFO -          dashboard at:        10.148.10.199:37923
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        10.148.10.199:33293
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-kabc0_hy
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-_s_9a9wi
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-jxg6ln9y
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.199:40149
distributed.worker - INFO -          Listening to:  tcp://10.148.10.199:40149
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.199:35989
distributed.worker - INFO -          dashboard at:        10.148.10.199:38633
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:44001
distributed.worker - INFO -          Listening to:  tcp://10.148.10.199:35989
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        10.148.10.199:42207
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-cy2jws4d
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-hua2bbn9
distributed.worker - INFO - -------------------------------------------------
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.199:39603
distributed.worker - INFO -          Listening to:  tcp://10.148.10.199:39603
distributed.worker - INFO -          dashboard at:        10.148.10.199:34011
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-ftc_4x3f
distributed.worker - INFO - -------------------------------------------------
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.199:36059
distributed.worker - INFO -          Listening to:  tcp://10.148.10.199:36059
distributed.worker - INFO -          dashboard at:        10.148.10.199:41481
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-pngk8qa8
distributed.worker - INFO - -------------------------------------------------
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.199:46853
distributed.worker - INFO -          Listening to:  tcp://10.148.10.199:46853
distributed.worker - INFO -          dashboard at:        10.148.10.199:43253
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-apktasaq
distributed.worker - INFO - -------------------------------------------------
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://10.148.10.199:39787
distributed.worker - INFO -          Listening to:  tcp://10.148.10.199:39787
distributed.worker - INFO -          dashboard at:        10.148.10.199:43621
distributed.worker - INFO - Waiting to connect to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          4
distributed.worker - INFO -                Memory:                   12.11 GB
distributed.worker - INFO -       Local Directory: /glade/u/home/apinard/ldcpy/docs/source/notebooks/dask-worker-space/worker-blblxigy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.148.10.15:44001
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Stopping worker at tcp://10.148.10.199:35989
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.199:40769'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.199:43573'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.199:41219'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.199:41997'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.199:34097'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.199:37151'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.199:33485'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.199:42233'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.148.10.199:33561'
/ncar/usr/jupyterhub/envs/cmip6-201910/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 54 leaked semaphores to clean up at shutdown
  len(cache))
